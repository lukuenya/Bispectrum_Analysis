{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1mQpNB3JJ8u95z7fGknV35IA6UN_mEKpm",
      "authorship_tag": "ABX9TyOS1onjio7FoPJVZCv1Zr4z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukuenya/Bispectrum_Analysis/blob/master/bispec_data_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iwmX36W2YsJE"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/audio_lanzhou_2015_org.zip\" -d \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/data.zip\" -d \"/content/data\""
      ],
      "metadata": {
        "id": "Xfilv-zlq_Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "from scipy.stats import entropy, skew, kurtosis\n",
        "import pandas as pd\n",
        "import cupy as cp\n",
        "import cupyx.scipy.signal as cusignal\n",
        "import cupyx.scipy.fft as cufft\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile  # Reading audio files can remain on CPU"
      ],
      "metadata": {
        "id": "aSUQiMVYY5h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fs = 44100  # Sampling frequency in Hz\n",
        "nfft = 512  # Adjust as needed\n",
        "\n",
        "# # Compute frequency bins once since fs is constant\n",
        "# freqs = np.fft.fftfreq(nfft, d=1/fs)\n",
        "\n",
        "\n",
        "def compute_bispectrum_gpu(audio_data, nfft=512, noverlap=None):\n",
        "    \"\"\"\n",
        "    Compute the bispectrum of an audio signal using GPU acceleration.\n",
        "\n",
        "    Parameters:\n",
        "    - audio_data: 1D numpy array of audio samples.\n",
        "    - nfft: FFT length.\n",
        "    - noverlap: Number of points to overlap between segments.\n",
        "\n",
        "    Returns:\n",
        "    - bispec: Bispectrum array on GPU.\n",
        "    \"\"\"\n",
        "    if noverlap is None:\n",
        "        noverlap = nfft // 2\n",
        "\n",
        "    # Generate window function on CPU\n",
        "    window_cpu = np.hanning(nfft)\n",
        "\n",
        "    # Segment the data on CPU\n",
        "    step = nfft - noverlap\n",
        "    shape = ((audio_data.size - noverlap) // step, nfft)\n",
        "    strides = (audio_data.strides[0] * step, audio_data.strides[0])\n",
        "    segments_cpu = np.lib.stride_tricks.as_strided(audio_data, shape=shape, strides=strides)\n",
        "\n",
        "    # Apply window function on CPU\n",
        "    segments_cpu = segments_cpu * window_cpu\n",
        "\n",
        "    # Transfer windowed segments to GPU\n",
        "    segments_gpu = cp.asarray(segments_cpu)\n",
        "\n",
        "    # Compute FFT on GPU\n",
        "    fft_segments = cufft.fft(segments_gpu, n=nfft, axis=1)\n",
        "\n",
        "    # Initialize bispectrum accumulator on GPU\n",
        "    bispec_accum = cp.zeros((nfft, nfft), dtype=cp.complex128)\n",
        "\n",
        "    # Compute bispectrum on GPU\n",
        "    num_segments = fft_segments.shape[0]\n",
        "    for i in range(num_segments):\n",
        "        X = fft_segments[i]\n",
        "        X_conj = cp.conj(X)\n",
        "        # Compute the triple product\n",
        "        outer_prod = X[:, None] * X[None, :]  # Outer product X(f1) * X(f2)\n",
        "        sum_indices = (cp.arange(nfft)[:, None] + cp.arange(nfft)) % nfft  # Indices for X*(f1 + f2)\n",
        "        X_sum_conj = X_conj[sum_indices]\n",
        "        bispec_accum += outer_prod * X_sum_conj\n",
        "\n",
        "    # Average over segments\n",
        "    bispec = bispec_accum / num_segments\n",
        "\n",
        "    return bispec\n"
      ],
      "metadata": {
        "id": "uigj3UagZMeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio_files_gpu(\n",
        "    dataset_path,\n",
        "    participant_types,\n",
        "    emotions,\n",
        "    session,\n",
        "    nfft=512,  # or 256\n",
        "    output_dir='/content/bispec_data_Interview'\n",
        "):\n",
        "    fs = 44100  # Sampling frequency in Hz\n",
        "    f_max = fs / 2  # Nyquist frequency\n",
        "    freqs = np.fft.fftfreq(nfft, d=1/fs)\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for participant_type in participant_types:\n",
        "        participant_type_path = os.path.join(dataset_path, participant_type)\n",
        "        if not os.path.exists(participant_type_path):\n",
        "            continue\n",
        "\n",
        "        # Create subdirectory for participant type in output directory\n",
        "        output_dir_participant = os.path.join(output_dir, participant_type)\n",
        "        if not os.path.exists(output_dir_participant):\n",
        "            os.makedirs(output_dir_participant)\n",
        "\n",
        "        participant_dirs = sorted(os.listdir(participant_type_path))\n",
        "\n",
        "        for participant in participant_dirs:\n",
        "            participant_path = os.path.join(participant_type_path, participant)\n",
        "            session_path = os.path.join(participant_path, session)\n",
        "            if not os.path.exists(session_path):\n",
        "                continue\n",
        "\n",
        "            for emotion in emotions:\n",
        "                emotion_path = os.path.join(session_path, emotion)\n",
        "                if not os.path.exists(emotion_path):\n",
        "                    continue\n",
        "\n",
        "                audio_files = [f for f in os.listdir(emotion_path) if f.endswith('.wav')]\n",
        "\n",
        "                # Initialize variables for accumulating bispectra\n",
        "                total_bispec_gpu = None\n",
        "                file_count = 0\n",
        "\n",
        "                for audio_file in audio_files:\n",
        "                    file_path = os.path.join(emotion_path, audio_file)\n",
        "                    try:\n",
        "                        fs_read, audio_data = wavfile.read(file_path)\n",
        "                        # Ensure audio_data is mono\n",
        "                        if audio_data.ndim > 1:\n",
        "                            audio_data = audio_data[:, 0]  # Use the first channel\n",
        "                        audio_data = audio_data.astype(np.float64)\n",
        "\n",
        "                        # Compute bispectrum using GPU\n",
        "                        bispec_gpu = compute_bispectrum_gpu(audio_data, nfft=nfft, noverlap=nfft // 2)\n",
        "\n",
        "                        # Accumulate bispectra\n",
        "                        if total_bispec_gpu is None:\n",
        "                            total_bispec_gpu = bispec_gpu\n",
        "                        else:\n",
        "                            total_bispec_gpu += bispec_gpu\n",
        "\n",
        "                        file_count += 1\n",
        "\n",
        "                        # Free GPU memory for this iteration\n",
        "                        del bispec_gpu\n",
        "                        cp._default_memory_pool.free_all_blocks()\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing {file_path}: {e}\")\n",
        "                        continue\n",
        "\n",
        "                # After processing all files for this participant, session, and emotion\n",
        "                if file_count > 0:\n",
        "                    # Compute the average bispectrum\n",
        "                    avg_bispec_gpu = total_bispec_gpu / file_count\n",
        "                    avg_bispec = avg_bispec_gpu.get()  # Transfer to CPU\n",
        "\n",
        "                    # Create meshgrid for f1 and f2 (in Hz)\n",
        "                    f_indices = np.arange(nfft)\n",
        "                    f1_indices, f2_indices = np.meshgrid(f_indices, f_indices, indexing='ij')\n",
        "\n",
        "                    f1_freqs = freqs[f1_indices]\n",
        "                    f2_freqs = freqs[f2_indices]\n",
        "\n",
        "                    # Create mask for the primary region based on the new conditions\n",
        "                    primary_region_mask = (\n",
        "                        (f1_freqs >= 0) &\n",
        "                        (f2_freqs >= 0) &\n",
        "                        (f1_freqs + f2_freqs <= f_max) &\n",
        "                        (f1_freqs <= f2_freqs)\n",
        "                    )\n",
        "\n",
        "                    # Initialize the primary region bispectrum with NaNs or zeros to maintain 2D shape\n",
        "                    avg_bispec_primary = np.full_like(avg_bispec, np.nan)  # Use np.nan or 0 if preferred\n",
        "                    avg_bispec_primary[primary_region_mask] = avg_bispec[primary_region_mask]\n",
        "\n",
        "                    # Save the bispectrum data for the primary region (2D)\n",
        "                    data_filename = f'{participant}_{session}_{emotion}_primary_bispectrum.npy'\n",
        "                    data_save_path = os.path.join(output_dir_participant, data_filename)\n",
        "                    np.save(data_save_path, avg_bispec_primary)\n",
        "                    print(f\"Primary region bispectrum data saved to {data_save_path}\")\n",
        "\n",
        "                    # Free GPU memory\n",
        "                    del avg_bispec_gpu, total_bispec_gpu\n",
        "                    cp._default_memory_pool.free_all_blocks()\n",
        "                else:\n",
        "                    print(f\"No valid audio files processed for {participant} - {session} - {emotion}\")\n"
      ],
      "metadata": {
        "id": "Hhgb-DFiZfQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataset path and parameters\n",
        "dataset_path = '/content/audio_lanzhou_2015_org'  # Update this path\n",
        "participant_types = ['MDD', 'HC']\n",
        "emotions = ['Positive', 'Neutral', 'Negative']\n",
        "session = 'Interview' # or 'Read_Vocabulary'\n",
        "nfft = 512 # or 256 Adjust as needed\n",
        "\n",
        "# Define the output directories\n",
        "output_dir = '/content/bispec_data_Interview'  # Update this path\n",
        "output_plot_dir = '/content/plots_RV'  # Update this path\n",
        "\n",
        "# Call the function to process audio files and save averaged bispectrum data and plots\n",
        "process_audio_files_gpu(\n",
        "    dataset_path,\n",
        "    participant_types,\n",
        "    emotions,\n",
        "    session,\n",
        "    nfft=nfft,\n",
        "    output_dir=output_dir,\n",
        "    #output_plot_dir=output_plot_dir\n",
        ")"
      ],
      "metadata": {
        "id": "ue6MGMD1bJfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_bispectrum_features(bispec, fs):\n",
        "    import numpy as np\n",
        "    from scipy.stats import entropy, skew, kurtosis\n",
        "\n",
        "    # Compute magnitude and phase\n",
        "    bispec_magnitude = np.abs(bispec)\n",
        "    bispec_phase = np.angle(bispec)\n",
        "\n",
        "    # Flatten the bispectrum magnitude and phase, removing NaNs\n",
        "    bispec_mag_flat = bispec_magnitude.flatten()\n",
        "    bispec_phase_flat = bispec_phase.flatten()\n",
        "\n",
        "    # Remove NaNs for calculations\n",
        "    bispec_mag_flat = bispec_mag_flat[~np.isnan(bispec_mag_flat)]\n",
        "    bispec_phase_flat = bispec_phase_flat[~np.isnan(bispec_phase_flat)]\n",
        "\n",
        "    # Check if the flattened array is empty after removing NaNs\n",
        "    if bispec_mag_flat.size == 0 or bispec_phase_flat.size == 0:\n",
        "        print(\"Bispectrum is empty after removing NaNs.\")\n",
        "        return {}\n",
        "\n",
        "    # Avoid log(0) by adding a small epsilon\n",
        "    eps = 1e-12\n",
        "\n",
        "    # Bispectral Magnitude Features\n",
        "    mean_mag = np.nanmean(bispec_mag_flat)\n",
        "    max_mag = np.nanmax(bispec_mag_flat)\n",
        "    sum_mag = np.nansum(bispec_mag_flat)\n",
        "    std_mag = np.nanstd(bispec_mag_flat)\n",
        "    skew_mag = skew(bispec_mag_flat)\n",
        "    kurt_mag = kurtosis(bispec_mag_flat)\n",
        "    spectral_flatness = np.exp(np.nanmean(np.log(bispec_mag_flat + eps))) / (mean_mag + eps)\n",
        "    entropy_mag = entropy(bispec_mag_flat + eps)\n",
        "\n",
        "    # Bispectral Phase Features\n",
        "    mean_phase = np.nanmean(bispec_phase_flat)\n",
        "    std_phase = np.nanstd(bispec_phase_flat)\n",
        "    skew_phase = skew(bispec_phase_flat)\n",
        "    kurt_phase = kurtosis(bispec_phase_flat)\n",
        "\n",
        "    # Quadratic Phase Coupling Features\n",
        "    N = bispec.shape[0]\n",
        "    if bispec_magnitude.size > 0:\n",
        "        indices_qpc = np.unravel_index(np.nanargmax(bispec_magnitude), bispec_magnitude.shape)\n",
        "        qpc_strength = bispec_magnitude[indices_qpc]\n",
        "        qpc_freqs = (indices_qpc[0] * fs / (N * 2), indices_qpc[1] * fs / (N * 2))\n",
        "    else:\n",
        "        qpc_strength = 0\n",
        "        qpc_freqs = (0, 0)\n",
        "    qpc_freq1, qpc_freq2 = qpc_freqs\n",
        "\n",
        "    # Frequency Band Features\n",
        "    freq_bins = np.fft.fftfreq(N * 2, d=1/fs)[:N]  # Assuming bispec is half-sized, N frequencies\n",
        "    bispec_magnitude_half = bispec_magnitude  # Since bispec is already half-sized\n",
        "\n",
        "    bands = {\n",
        "        'low': (0, 1000),\n",
        "        'mid': (1000, 5000),\n",
        "        'high': (5000, fs/2)\n",
        "    }\n",
        "\n",
        "    band_energies = {}\n",
        "    for band_name, (fmin, fmax) in bands.items():\n",
        "        idx = np.where((freq_bins >= fmin) & (freq_bins < fmax))[0]\n",
        "        if len(idx) > 0:\n",
        "            band_energy = np.nansum(bispec_magnitude_half[np.ix_(idx, idx)])\n",
        "        else:\n",
        "            band_energy = 0\n",
        "        band_energies[f'band_energy_{band_name}'] = band_energy\n",
        "\n",
        "    # Bispectrum Peaks\n",
        "    threshold = mean_mag + 2 * std_mag\n",
        "    peaks_indices = np.where(bispec_mag_flat > threshold)[0]\n",
        "    num_peaks = len(peaks_indices)\n",
        "\n",
        "    # If peaks are found, compute additional features\n",
        "    if num_peaks > 0:\n",
        "        peak_magnitudes = bispec_mag_flat[peaks_indices]\n",
        "        max_peak_intensity = np.nanmax(peak_magnitudes)\n",
        "        mean_peak_intensity = np.nanmean(peak_magnitudes)\n",
        "        median_peak_intensity = np.nanmedian(peak_magnitudes)\n",
        "        std_peak_intensity = np.nanstd(peak_magnitudes)\n",
        "        skew_peak_intensity = skew(peak_magnitudes)\n",
        "        kurt_peak_intensity = kurtosis(peak_magnitudes)\n",
        "    else:\n",
        "        max_peak_intensity = 0\n",
        "        mean_peak_intensity = 0\n",
        "        median_peak_intensity = 0\n",
        "        std_peak_intensity = 0\n",
        "        skew_peak_intensity = 0\n",
        "        kurt_peak_intensity = 0\n",
        "\n",
        "    # Reshape bispectrum magnitude to 2D for peak location analysis\n",
        "    bispec_magnitude_2d = bispec_magnitude  # Assuming it's already 2D\n",
        "\n",
        "    # Get the coordinates of the peaks\n",
        "    peak_coords = np.argwhere(bispec_magnitude_2d > threshold)\n",
        "\n",
        "    # Frequencies corresponding to the bispectrum axes\n",
        "    freqs = freq_bins  # frequencies corresponding to the axes\n",
        "\n",
        "    # Extract frequencies of the top N peaks\n",
        "    N_peaks = 5  # Number of top peaks to consider\n",
        "    if num_peaks > 0:\n",
        "        # Sort peaks by magnitude\n",
        "        sorted_peak_indices = np.argsort(-peak_magnitudes)\n",
        "        top_n_indices = peaks_indices[sorted_peak_indices[:N_peaks]]\n",
        "        # Convert flat indices back to 2D coordinates\n",
        "        top_n_coords = np.unravel_index(top_n_indices, bispec_magnitude_2d.shape)\n",
        "        top_n_freqs = [(freqs[i], freqs[j]) for i, j in zip(*top_n_coords)]\n",
        "    else:\n",
        "        top_n_freqs = []\n",
        "\n",
        "    # Collect all features into a dictionary\n",
        "    features = {\n",
        "        'mean_mag': mean_mag,\n",
        "        'max_mag': max_mag,\n",
        "        'sum_mag': sum_mag,\n",
        "        'std_mag': std_mag,\n",
        "        'skew_mag': skew_mag,\n",
        "        'kurt_mag': kurt_mag,\n",
        "        'spectral_flatness': spectral_flatness,\n",
        "        'entropy_mag': entropy_mag,\n",
        "        'mean_phase': mean_phase,\n",
        "        'std_phase': std_phase,\n",
        "        'skew_phase': skew_phase,\n",
        "        'kurt_phase': kurt_phase,\n",
        "        'qpc_strength': qpc_strength,\n",
        "        'qpc_freq1': qpc_freq1,\n",
        "        'qpc_freq2': qpc_freq2,\n",
        "        **band_energies,\n",
        "        'num_peaks': num_peaks,\n",
        "        'max_peak_intensity': max_peak_intensity,\n",
        "        'mean_peak_intensity': mean_peak_intensity,\n",
        "        'median_peak_intensity': median_peak_intensity,\n",
        "        'std_peak_intensity': std_peak_intensity,\n",
        "        'skew_peak_intensity': skew_peak_intensity,\n",
        "        'kurt_peak_intensity': kurt_peak_intensity,\n",
        "    }\n",
        "\n",
        "    # Add frequencies of top N peaks to the features\n",
        "    for idx, (f1, f2) in enumerate(top_n_freqs):\n",
        "        features[f'top_peak_{idx+1}_freq1'] = f1\n",
        "        features[f'top_peak_{idx+1}_freq2'] = f2\n",
        "\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "2dCF26yZSJgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths and parameters\n",
        "output_dir = '/content/bispec_data_RV'  # Update with your output directory\n",
        "session = 'Read_Vocabulary' # or 'Interview'\n",
        "participant_types = ['MDD', 'HC']\n",
        "emotions = ['Positive', 'Neutral', 'Negative']\n",
        "\n",
        "# Initialize a list to store features\n",
        "features_list = []\n",
        "\n",
        "# Load bispectrum data and extract features\n",
        "for participant_type in participant_types:\n",
        "    participant_output_dir = os.path.join(output_dir, participant_type)\n",
        "    if not os.path.exists(participant_output_dir):\n",
        "        continue\n",
        "\n",
        "    # Assign label based on participant type\n",
        "    label = 1 if participant_type == 'MDD' else 0\n",
        "\n",
        "    # List participants in the directory\n",
        "    participant_files = os.listdir(participant_output_dir)\n",
        "    for bispec_file in participant_files:\n",
        "        bispec_path = os.path.join(participant_output_dir, bispec_file)\n",
        "\n",
        "        # Ensure we're only processing .npy files\n",
        "        if not bispec_file.endswith('_primary_bispectrum.npy'):\n",
        "            continue\n",
        "\n",
        "        # Load bispectrum data\n",
        "        bispec = np.load(bispec_path)\n",
        "\n",
        "        # Extract participant ID and emotion from filename\n",
        "        filename_parts = bispec_file.split('_')\n",
        "        participant = filename_parts[0]\n",
        "        emotion = filename_parts[3] if session == 'Read_Vocabulary' else filename_parts[2]\n",
        "\n",
        "        # Sampling frequency\n",
        "        fs = 44100  # Update if necessary\n",
        "\n",
        "        # Extract features\n",
        "        features = extract_bispectrum_features(bispec, fs)\n",
        "\n",
        "        # Add additional information to features\n",
        "        features['participant'] = participant\n",
        "        features['participant_type'] = participant_type\n",
        "        features['session'] = session\n",
        "        features['emotion'] = emotion\n",
        "        features['label'] = label\n",
        "\n",
        "        # Append features to the list\n",
        "        features_list.append(features)\n",
        "\n",
        "# Convert the list of features to a DataFrame\n",
        "df_features = pd.DataFrame(features_list)\n",
        "\n",
        "# Save the DataFrame to an Excel or CSV file\n",
        "excel_file = '/content/features_RV.xlsx'  # Update the path\n",
        "df_features.to_excel(excel_file, index=False)\n",
        "print(f\"Features saved to {excel_file}\")\n",
        "\n",
        "# # Optionally, save to CSV\n",
        "# csv_file = '/path/to/features.csv'  # Update the path\n",
        "# df_features.to_csv(csv_file, index=False)\n",
        "# print(f\"Features saved to {csv_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L0TeMebbdh2",
        "outputId": "0d239f98-fa1c-4f9e-c380-7450f6be8eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to /content/features_RV.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/bispec_data_RV', 'zip', '/content/bispec_data_RV')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fuUt7z3Jn7yJ",
        "outputId": "57b01a00-59fa-4b4d-81ba-7b2aa6f73d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/bispec_data_RV.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z-QwwgW_3lBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_bispectrum(bispec, freqs, max_freq=fs/2, levels=30, cmap='jet', title='Bispectrum', save_path=None):\n",
        "    # Compute magnitude\n",
        "    magnitude = np.abs(bispec)\n",
        "\n",
        "    # Limit frequency range\n",
        "    freq_indices = np.where((freqs >= 0) & (freqs <= max_freq))[0]\n",
        "    freqs_limited = freqs[freq_indices]\n",
        "    magnitude_limited = magnitude[np.ix_(freq_indices, freq_indices)]\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    CS = plt.contour(freqs_limited, freqs_limited, magnitude_limited, levels=levels, cmap=cmap)\n",
        "    plt.colorbar(label='Magnitude')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('f1 (Hz)')\n",
        "    plt.ylabel('f2 (Hz)')\n",
        "    plt.xlim([0, max_freq])\n",
        "    plt.ylim([0, max_freq])\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Add diagonal line where f1 = f2\n",
        "    plt.plot([0, max_freq], [0, max_freq], 'k--', linewidth=1)  # Dashed black line\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300)\n",
        "        plt.close()\n",
        "        print(f\"Plot saved to {save_path}\")\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "XPUBfCtw6h_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_all_bispectra(\n",
        "    bispec_data_dir='/content/bispec_data_Interview',  # Update with your bispectrum data directory\n",
        "    plots_output_dir='/content/plots_Interview',      # Update with your desired plots output directory\n",
        "    participant_types=['MDD', 'HC'],                  # Replace with your participant types\n",
        "    session='Interview',                              # Replace with your session name\n",
        "    emotions=['Positive', 'Neutral', 'Negative'],     # Replace with your emotions\n",
        "    nfft=512,                                         # FFT length used in bispectrum computation\n",
        "    fs=44100,                                         # Sampling frequency in Hz\n",
        "    default_max_freq=1500,                           # Default max frequency for plotting\n",
        "    percentile=99,                                   # Percentile for determining max_freq\n",
        "    levels=30,                                        # Number of contour levels in plots\n",
        "    cmap='jet'                                     # Colormap for the plots\n",
        "):\n",
        "    \"\"\"\n",
        "    Load bispectrum data, plot each bispectrum, and save the plots and metadata.\n",
        "\n",
        "    Parameters:\n",
        "    - bispec_data_dir: Directory containing bispectrum data organized by participant type.\n",
        "    - plots_output_dir: Directory to save the bispectrum plots.\n",
        "    - participant_types: List of participant types (e.g., ['MDD', 'HC']).\n",
        "    - session: Session identifier (e.g., 'Interview').\n",
        "    - emotions: List of emotions (e.g., ['Positive', 'Neutral', 'Negative']).\n",
        "    - nfft: FFT length used in bispectrum computation.\n",
        "    - fs: Sampling frequency in Hz.\n",
        "    - default_max_freq: Default maximum frequency for plotting.\n",
        "    - percentile: Percentile for determining max_freq based on bispectral magnitude.\n",
        "    - levels: Number of contour levels in the plots.\n",
        "    - cmap: Colormap for the plots.\n",
        "    - excel_output_path: Path to save the Excel file containing plot metadata.\n",
        "    \"\"\"\n",
        "\n",
        "    # Iterate through each participant type\n",
        "    for participant_type in participant_types:\n",
        "        participant_output_dir = os.path.join(bispec_data_dir, participant_type)\n",
        "        if not os.path.exists(participant_output_dir):\n",
        "            print(f\"Participant type directory does not exist: {participant_output_dir}\")\n",
        "            continue\n",
        "\n",
        "        # Create corresponding plot directory for the participant type\n",
        "        plots_participant_type_dir = os.path.join(plots_output_dir, participant_type)\n",
        "        os.makedirs(plots_participant_type_dir, exist_ok=True)\n",
        "\n",
        "        # List all bispectrum files in the participant type directory\n",
        "        bispec_files = [f for f in os.listdir(participant_output_dir) if f.endswith('_primary_bispectrum.npy')]\n",
        "\n",
        "        for bispec_file in bispec_files:\n",
        "            bispec_path = os.path.join(participant_output_dir, bispec_file)\n",
        "\n",
        "            # Parse participant, session, and emotion from filename\n",
        "            # Expected filename format: participant1_Interview_Positive_primary_bispectrum.npy\n",
        "            filename_parts = bispec_file.split('_')\n",
        "            if len(filename_parts) < 4:\n",
        "                print(f\"Filename does not match expected format and will be skipped: {bispec_file}\")\n",
        "                continue\n",
        "            participant = filename_parts[0]\n",
        "            session_parsed = filename_parts[1]\n",
        "            emotion = filename_parts[3] if session == 'Read_Vocabulary' else filename_parts[2]\n",
        "\n",
        "            # Load bispectrum data\n",
        "            try:\n",
        "                bispec = np.load(bispec_path)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading bispectrum file {bispec_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "            # Generate frequency bins\n",
        "            freqs = np.fft.fftfreq(nfft, d=1/fs)[:nfft//2]\n",
        "\n",
        "            # # Determine max_freq using the helper function\n",
        "            # max_freq = determine_max_freq(\n",
        "            #     avg_bispec_positive=bispec,\n",
        "            #     freqs=freqs,\n",
        "            #     default_max_freq=default_max_freq,\n",
        "            #     percentile=percentile\n",
        "            # )\n",
        "\n",
        "            # Define plot title\n",
        "            title = f'Bispectrum - {participant} - {session_parsed} - {emotion}'\n",
        "\n",
        "            # Define plot filename and path\n",
        "            plot_filename = f'{participant}_{session_parsed}_{emotion}_average_bispectrum.png'\n",
        "            plots_participant_dir = os.path.join(plots_participant_type_dir)\n",
        "            os.makedirs(plots_participant_dir, exist_ok=True)\n",
        "            plot_save_path = os.path.join(plots_participant_dir, plot_filename)\n",
        "\n",
        "    #         # Plot and save the bispectrum\n",
        "    #         plot_bispectrum(\n",
        "    #             avg_bispec=bispec,\n",
        "    #             freqs=freqs,\n",
        "    #             max_freq=max_freq,\n",
        "    #             levels=levels,\n",
        "    #             cmap=cmap,\n",
        "    #             title=title,\n",
        "    #             save_path=plot_save_path\n",
        "    #         )\n",
        "\n",
        "    #         # Record metadata\n",
        "    #         plot_info = {\n",
        "    #             'participant_type': participant_type,\n",
        "    #             'participant': participant,\n",
        "    #             'session': session_parsed,\n",
        "    #             'emotion': emotion,\n",
        "    #             'bispectra_path': bispec_path,\n",
        "    #             'plot_path': plot_save_path,\n",
        "    #             'max_freq_used': max_freq\n",
        "    #         }\n",
        "    #         plot_metadata.append(plot_info)\n",
        "\n",
        "    # # Convert the metadata list to a DataFrame\n",
        "    # df_metadata = pd.DataFrame(plot_metadata)\n",
        "\n",
        "    # # Save the DataFrame to an Excel file\n",
        "    # try:\n",
        "    #     df_metadata.to_excel(excel_output_path, index=False)\n",
        "    #     print(f\"Plot metadata saved to {excel_output_path}\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\"Error saving Excel file {excel_output_path}: {e}\")\n"
      ],
      "metadata": {
        "id": "ntip_qkV6zvi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}