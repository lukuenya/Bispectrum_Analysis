{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1Nu-VPm9Of4tzAo3HYtZG6X07MjmjeKo9",
      "authorship_tag": "ABX9TyM7LQAbsLF6NG8akqJnP13W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukuenya/Bispectrum_Analysis/blob/master/Bispectrum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import cupy as cp\n",
        "# import scipy.io.wavfile as wavfile\n",
        "# import matplotlib.pyplot as plt\n",
        "# import os\n",
        "\n",
        "# # Parameters for bispectrum estimation\n",
        "# segment_length = 1024\n",
        "# overlap = segment_length // 2\n",
        "# step = segment_length - overlap\n",
        "# window = cp.hanning(segment_length)\n",
        "# N = segment_length\n",
        "\n",
        "\n",
        "# # Function to compute the bispectrum of a signal\n",
        "# def compute_bispectrum(data, fs):\n",
        "#     # Normalize the data\n",
        "#     max_abs = cp.max(cp.abs(data))\n",
        "#     if max_abs == 0:\n",
        "#         return cp.zeros((N, N), dtype=cp.complex128)\n",
        "#     data = data / max_abs\n",
        "#     num_segments = (len(data) - overlap) // step\n",
        "#     bispec_accum = cp.zeros((N, N), dtype=cp.complex128)\n",
        "#     count = 0\n",
        "\n",
        "#     for i in range(num_segments):\n",
        "#         start = i * step\n",
        "#         end = start + segment_length\n",
        "#         segment = data[start:end]\n",
        "#         if len(segment) < segment_length:\n",
        "#             break\n",
        "#         segment = segment * window\n",
        "#         X = cp.fft.fft(segment, n=N)\n",
        "#         X1 = X[:, cp.newaxis]\n",
        "#         X2 = X[cp.newaxis, :]\n",
        "#         indices_sum = (cp.arange(N)[:, cp.newaxis] + cp.arange(N)[cp.newaxis, :]) % N\n",
        "#         X3 = cp.conj(X[indices_sum])\n",
        "#         triple_product = X1 * X2 * X3\n",
        "#         bispec_accum += triple_product\n",
        "#         count += 1\n",
        "\n",
        "#     if count > 0:\n",
        "#         bispec = bispec_accum / count\n",
        "#     else:\n",
        "#         bispec = bispec_accum\n",
        "#     return bispec\n",
        "\n",
        "# # Function to visualize and optionally save the bispectrum\n",
        "# def visualize_bispectrum(bispec, fs, title, save_path=None):\n",
        "#     bispec_magnitude = cp.abs(bispec)\n",
        "#     bispec_magnitude_db = 10 * cp.log10(bispec_magnitude + 1e-12)\n",
        "#     bispec_magnitude_db_shifted = cp.fft.fftshift(bispec_magnitude_db)\n",
        "#     freq_bins = cp.fft.fftfreq(N, d=1/fs)\n",
        "#     freq_bins_shifted = cp.fft.fftshift(freq_bins)\n",
        "\n",
        "#     # Convert to CPU arrays for plotting\n",
        "#     bispec_magnitude_db_shifted_cpu = cp.asnumpy(bispec_magnitude_db_shifted)\n",
        "#     freq_bins_shifted_cpu = cp.asnumpy(freq_bins_shifted)\n",
        "\n",
        "#     plt.figure(figsize=(10, 8))\n",
        "#     extent = [freq_bins_shifted_cpu[0], freq_bins_shifted_cpu[-1],\n",
        "#               freq_bins_shifted_cpu[0], freq_bins_shifted_cpu[-1]]\n",
        "#     plt.imshow(bispec_magnitude_db_shifted_cpu, extent=extent, origin='lower',\n",
        "#                aspect='auto', cmap='jet')\n",
        "#     plt.xlabel('Frequency f1 (Hz)')\n",
        "#     plt.ylabel('Frequency f2 (Hz)')\n",
        "#     plt.title(title)\n",
        "#     plt.colorbar(label='Magnitude (dB)')\n",
        "#     if save_path:\n",
        "#         plt.savefig(save_path)\n",
        "#         plt.close()\n",
        "#     else:\n",
        "#         plt.show()\n",
        "\n",
        "\n",
        "# # Main script\n",
        "# # Set the path to your dataset folder\n",
        "# dataset_path = '/content/Audio_lanzhou_2015_org'  # Update this path\n",
        "\n",
        "# # Directory to save plots\n",
        "# output_dir = '/content/results'  # Update this path if needed\n",
        "\n",
        "# # Participant types and emotions\n",
        "# participant_types = ['MDD', 'HC']\n",
        "# emotions = ['Positive', 'Neutral', 'Negative']\n",
        "\n",
        "# # Specify the session to process\n",
        "# session = 'Interview'  # Manually set to 'Interview' or 'Read_Vocabulary'\n",
        "\n",
        "# # Process each participant type\n",
        "# for participant_type in participant_types:\n",
        "#     participant_type_path = os.path.join(dataset_path, participant_type)\n",
        "#     if not os.path.exists(participant_type_path):\n",
        "#         continue\n",
        "\n",
        "#     # Get list of participant directories\n",
        "#     participant_dirs = [d for d in os.listdir(participant_type_path) if os.path.isdir(os.path.join(participant_type_path, d))]\n",
        "#     participant_dirs.sort()  # Ensure consistent order\n",
        "\n",
        "#     # Process each participant\n",
        "#     for participant in participant_dirs:\n",
        "#         participant_path = os.path.join(participant_type_path, participant)\n",
        "#         print(f\"Processing participant {participant} ({participant_type})...\")\n",
        "\n",
        "#         # Process the specified session\n",
        "#         session_path = os.path.join(participant_path, session)\n",
        "#         if not os.path.exists(session_path):\n",
        "#             continue\n",
        "\n",
        "#         # Process each emotion\n",
        "#         for emotion in emotions:\n",
        "#             emotion_path = os.path.join(session_path, emotion)\n",
        "#             if not os.path.exists(emotion_path):\n",
        "#                 continue\n",
        "\n",
        "#             print(f\"  Processing {session} - {emotion}\")\n",
        "\n",
        "#             # Initialize accumulator for bispectra\n",
        "#             bispec_sums = cp.zeros((N, N), dtype=cp.complex128)\n",
        "#             count = 0\n",
        "\n",
        "#             # Get list of .wav files\n",
        "#             recording_files = [f for f in os.listdir(emotion_path) if f.endswith('.wav')]\n",
        "#             recording_files.sort()  # Ensure consistent order\n",
        "\n",
        "#             # Process each recording\n",
        "#             for recording_file in recording_files:\n",
        "#                 file_path = os.path.join(emotion_path, recording_file)\n",
        "#                 try:\n",
        "#                     # Read the audio file\n",
        "#                     fs, data = wavfile.read(file_path)\n",
        "#                     if len(data.shape) > 1:\n",
        "#                         data = data[:, 0]  # Take one channel if stereo\n",
        "#                 except Exception as e:\n",
        "#                     print(f\"    Warning: Could not read file {file_path}. Skipping. Error: {e}\")\n",
        "#                     continue\n",
        "\n",
        "#                 # Check if data is empty\n",
        "#                 if len(data) == 0:\n",
        "#                     print(f\"    Warning: Empty audio data in file {file_path}. Skipping.\")\n",
        "#                     continue\n",
        "\n",
        "#                 # Convert data to CuPy array\n",
        "#                 data = cp.asarray(data, dtype=cp.float64)\n",
        "\n",
        "#                 # Compute the bispectrum\n",
        "#                 bispec = compute_bispectrum(data, fs)\n",
        "#                 bispec_sums += bispec\n",
        "#                 count += 1\n",
        "\n",
        "#             # Compute average bispectrum for participant and state\n",
        "#             if count > 0:\n",
        "#                 avg_bispec = bispec_sums / count\n",
        "\n",
        "#                 # Create output directory for the participant type\n",
        "#                 participant_output_dir = os.path.join(output_dir, 'results', session.lower(), participant_type)\n",
        "#                 os.makedirs(participant_output_dir, exist_ok=True)\n",
        "\n",
        "#                 # Visualize average bispectrum\n",
        "#                 title = f'Average Bispectrum of {participant} ({participant_type}) - {session} - {emotion}'\n",
        "#                 save_filename = f'{participant}_{session}_{emotion}_average_bispectrum.png'\n",
        "#                 save_path = os.path.join(participant_output_dir, save_filename)\n",
        "#                 visualize_bispectrum(avg_bispec, fs, title, save_path)\n",
        "#                 print(f\"    Saved bispectrum plot to {save_path}\")\n",
        "#             else:\n",
        "#                 print(f\"    No valid recordings for {participant} ({participant_type}) - {session} - {emotion}.\")\n",
        "\n",
        "# print('Complete')\n"
      ],
      "metadata": {
        "id": "rhZS6M_ASe87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy as cp  # Use CuPy instead of NumPy for GPU acceleration\n",
        "import scipy.io.wavfile as wavfile\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Parameters for bispectrum estimation\n",
        "segment_length = 1024\n",
        "overlap = segment_length // 2\n",
        "step = segment_length - overlap\n",
        "window = cp.hanning(segment_length)\n",
        "N = segment_length\n",
        "\n",
        "# Function to compute the bispectrum of a signal using CuPy\n",
        "def compute_bispectrum(data, fs):\n",
        "    # Normalize the data\n",
        "    max_abs = cp.max(cp.abs(data))\n",
        "    if max_abs == 0:\n",
        "        return cp.zeros((N, N), dtype=cp.complex128)\n",
        "    data = data / max_abs\n",
        "    num_segments = (len(data) - overlap) // step\n",
        "    bispec_accum = cp.zeros((N, N), dtype=cp.complex128)\n",
        "    count = 0\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        start = i * step\n",
        "        end = start + segment_length\n",
        "        segment = data[start:end]\n",
        "        if len(segment) < segment_length:\n",
        "            break\n",
        "        segment = segment * window\n",
        "        X = cp.fft.fft(segment, n=N)\n",
        "        X1 = X[:, cp.newaxis]\n",
        "        X2 = X[cp.newaxis, :]\n",
        "        indices_sum = (cp.arange(N)[:, cp.newaxis] + cp.arange(N)[cp.newaxis, :]) % N\n",
        "        X3 = cp.conj(X[indices_sum])\n",
        "        triple_product = X1 * X2 * X3\n",
        "        bispec_accum += triple_product\n",
        "        count += 1\n",
        "\n",
        "    if count > 0:\n",
        "        bispec = bispec_accum / count\n",
        "    else:\n",
        "        bispec = bispec_accum\n",
        "    return bispec\n",
        "\n",
        "# Set the path to your dataset folder\n",
        "dataset_path = '/kaggle/input/modma-org/audio_lanzhou_2015_org'  # Update this path\n",
        "\n",
        "# Directory to save plots and bispectrum data\n",
        "output_dir = '/kaggle/working'  # Update this path if needed\n",
        "\n",
        "# Participant types and emotions\n",
        "participant_types = ['MDD', 'HC']\n",
        "emotions = ['Positive', 'Neutral', 'Negative']\n",
        "\n",
        "# Specify the session to process\n",
        "session = 'Interview'  # Manually set to 'Interview' or 'Read_Vocabulary'\n",
        "\n",
        "# Process each participant type\n",
        "for participant_type in participant_types:\n",
        "    participant_type_path = os.path.join(dataset_path, participant_type)\n",
        "    if not os.path.exists(participant_type_path):\n",
        "        continue\n",
        "\n",
        "    # Get list of participant directories\n",
        "    participant_dirs = [d for d in os.listdir(participant_type_path) if os.path.isdir(os.path.join(participant_type_path, d))]\n",
        "    participant_dirs.sort()  # Ensure consistent order\n",
        "\n",
        "    # Process each participant\n",
        "    for participant in participant_dirs:\n",
        "        participant_path = os.path.join(participant_type_path, participant)\n",
        "        print(f\"Processing participant {participant} ({participant_type})...\")\n",
        "\n",
        "        # Process the specified session\n",
        "        session_path = os.path.join(participant_path, session)\n",
        "        if not os.path.exists(session_path):\n",
        "            continue\n",
        "\n",
        "        # Process each emotion\n",
        "        for emotion in emotions:\n",
        "            emotion_path = os.path.join(session_path, emotion)\n",
        "            if not os.path.exists(emotion_path):\n",
        "                continue\n",
        "\n",
        "            print(f\"  Processing {session} - {emotion}\")\n",
        "\n",
        "            # Initialize accumulator for bispectra\n",
        "            bispec_sums = cp.zeros((N, N), dtype=cp.complex128)\n",
        "            count = 0\n",
        "\n",
        "            # Get list of .wav files\n",
        "            recording_files = [f for f in os.listdir(emotion_path) if f.endswith('.wav')]\n",
        "            recording_files.sort()  # Ensure consistent order\n",
        "\n",
        "            # Process each recording\n",
        "            for recording_file in recording_files:\n",
        "                file_path = os.path.join(emotion_path, recording_file)\n",
        "                try:\n",
        "                    # Read the audio file\n",
        "                    fs, data = wavfile.read(file_path)\n",
        "                    if len(data.shape) > 1:\n",
        "                        data = data[:, 0]  # Take one channel if stereo\n",
        "                    data = data.astype(cp.float64)  # Ensure data is float64\n",
        "                except Exception as e:\n",
        "                    print(f\"    Warning: Could not read file {file_path}. Skipping. Error: {e}\")\n",
        "                    continue\n",
        "\n",
        "                # Check if data is empty\n",
        "                if len(data) == 0:\n",
        "                    print(f\"    Warning: Empty audio data in file {file_path}. Skipping.\")\n",
        "                    continue\n",
        "\n",
        "                # Convert data to CuPy array\n",
        "                data = cp.asarray(data)\n",
        "\n",
        "                # Compute the bispectrum\n",
        "                bispec = compute_bispectrum(data, fs)\n",
        "                bispec_sums += bispec\n",
        "                count += 1\n",
        "\n",
        "                # Free up memory\n",
        "                del data, bispec\n",
        "                cp._default_memory_pool.free_all_blocks()\n",
        "\n",
        "            # Compute average bispectrum for participant and state\n",
        "            if count > 0:\n",
        "                avg_bispec = bispec_sums / count\n",
        "\n",
        "                # Create output directory for the participant type\n",
        "                participant_output_dir = os.path.join(output_dir, 'results', session.lower(), participant_type)\n",
        "                os.makedirs(participant_output_dir, exist_ok=True)\n",
        "\n",
        "                # Save the bispectrum data\n",
        "                bispec_filename = f'{participant}_{session}_{emotion}_average_bispectrum.npy'\n",
        "                bispec_save_path = os.path.join(participant_output_dir, bispec_filename)\n",
        "\n",
        "                # Transfer bispectrum data to CPU for saving\n",
        "                avg_bispec_cpu = cp.asnumpy(avg_bispec)\n",
        "                np.save(bispec_save_path, avg_bispec_cpu)\n",
        "                print(f\"    Saved bispectrum data to {bispec_save_path}\")\n",
        "\n",
        "                # Free up memory\n",
        "                del avg_bispec, avg_bispec_cpu\n",
        "                cp._default_memory_pool.free_all_blocks()\n",
        "\n",
        "            else:\n",
        "                print(f\"    No valid recordings for {participant} ({participant_type}) - {session} - {emotion}.\")\n",
        "\n",
        "print('Complete')\n"
      ],
      "metadata": {
        "id": "thkzX2klUG_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from scipy.stats import skew, kurtosis, entropy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# Function to extract features from bispectrum data\n",
        "def extract_bispectrum_features(bispec, fs):\n",
        "    # [Include the updated feature extraction function from previous messages]\n",
        "    # Compute magnitude and phase\n",
        "    bispec_magnitude = np.abs(bispec)\n",
        "    bispec_phase = np.angle(bispec)\n",
        "\n",
        "    # Flatten the bispectrum magnitude and phase\n",
        "    bispec_mag_flat = bispec_magnitude.flatten()\n",
        "    bispec_phase_flat = bispec_phase.flatten()\n",
        "\n",
        "    # Avoid log(0) by adding a small epsilon\n",
        "    eps = 1e-12\n",
        "\n",
        "    # Bispectral Magnitude Features\n",
        "    mean_mag = np.mean(bispec_mag_flat)\n",
        "    max_mag = np.max(bispec_mag_flat)\n",
        "    sum_mag = np.sum(bispec_mag_flat)\n",
        "    spectral_flatness = np.exp(np.mean(np.log(bispec_mag_flat + eps))) / (mean_mag + eps)\n",
        "    entropy_mag = entropy(bispec_mag_flat + eps)\n",
        "\n",
        "    # Bispectral Phase Features\n",
        "    mean_phase = np.mean(bispec_phase_flat)\n",
        "    std_phase = np.std(bispec_phase_flat)\n",
        "    skew_phase = skew(bispec_phase_flat)\n",
        "    kurt_phase = kurtosis(bispec_phase_flat)\n",
        "\n",
        "    # Quadratic Phase Coupling Features\n",
        "    N = bispec.shape[0]  # Ensure N is defined\n",
        "    indices_qpc = np.unravel_index(np.argmax(bispec_magnitude), bispec_magnitude.shape)\n",
        "    qpc_strength = bispec_magnitude[indices_qpc]\n",
        "    qpc_freqs = (indices_qpc[0] * fs / N, indices_qpc[1] * fs / N)\n",
        "\n",
        "    # Frequency Band Features\n",
        "    freq_bins = np.fft.fftfreq(N, d=1/fs)\n",
        "    freq_bins = freq_bins[:N//2]\n",
        "    bispec_magnitude_half = bispec_magnitude[:N//2, :N//2]\n",
        "\n",
        "    bands = {\n",
        "        'low': (0, 1000),\n",
        "        'mid': (1000, 5000),\n",
        "        'high': (5000, fs/2)\n",
        "    }\n",
        "\n",
        "    band_energies = {}\n",
        "    for band_name, (fmin, fmax) in bands.items():\n",
        "        idx = np.where((freq_bins >= fmin) & (freq_bins < fmax))[0]\n",
        "        band_energy = np.sum(bispec_magnitude_half[np.ix_(idx, idx)])\n",
        "        band_energies[f'band_energy_{band_name}'] = band_energy\n",
        "\n",
        "    # Bispectrum Peaks\n",
        "    threshold = mean_mag + 2 * np.std(bispec_mag_flat)\n",
        "    num_peaks = np.sum(bispec_mag_flat > threshold)\n",
        "\n",
        "    # Statistical Features\n",
        "    std_mag = np.std(bispec_mag_flat)\n",
        "    skew_mag = skew(bispec_mag_flat)\n",
        "    kurt_mag = kurtosis(bispec_mag_flat)\n",
        "\n",
        "    # Collect all features into a dictionary\n",
        "    features = {\n",
        "        'mean_mag': mean_mag,\n",
        "        'max_mag': max_mag,\n",
        "        'sum_mag': sum_mag,\n",
        "        'spectral_flatness': spectral_flatness,\n",
        "        'entropy_mag': entropy_mag,\n",
        "        'mean_phase': mean_phase,\n",
        "        'std_phase': std_phase,\n",
        "        'skew_phase': skew_phase,\n",
        "        'kurt_phase': kurt_phase,\n",
        "        'qpc_strength': qpc_strength,\n",
        "        'qpc_freq1': qpc_freqs[0],\n",
        "        'qpc_freq2': qpc_freqs[1],\n",
        "        **band_energies,\n",
        "        'num_peaks': num_peaks,\n",
        "        'std_mag': std_mag,\n",
        "        'skew_mag': skew_mag,\n",
        "        'kurt_mag': kurt_mag,\n",
        "    }\n",
        "\n",
        "    return features\n",
        "\n",
        "# Paths and parameters\n",
        "output_dir = '/kaggle/working'  # Update if necessary\n",
        "session = 'Interview'  # Or 'Read_Vocabulary'\n",
        "participant_types = ['MDD', 'HC']\n",
        "emotions = ['Positive', 'Neutral', 'Negative']\n",
        "\n",
        "# Initialize lists to store features and labels\n",
        "feature_list = []\n",
        "label_list = []\n",
        "\n",
        "# Load bispectrum data and extract features\n",
        "for participant_type in participant_types:\n",
        "    participant_output_dir = os.path.join(output_dir, 'results', session.lower(), participant_type)\n",
        "    if not os.path.exists(participant_output_dir):\n",
        "        continue\n",
        "\n",
        "    # Assign label based on participant type\n",
        "    label = 1 if participant_type == 'MDD' else 0\n",
        "\n",
        "    # Get list of bispectrum files\n",
        "    bispec_files = [f for f in os.listdir(participant_output_dir) if f.endswith('_average_bispectrum.npy')]\n",
        "\n",
        "    for bispec_file in bispec_files:\n",
        "        bispec_path = os.path.join(participant_output_dir, bispec_file)\n",
        "\n",
        "        # Load bispectrum data\n",
        "        bispec = np.load(bispec_path)\n",
        "\n",
        "        # Extract participant ID and emotion from filename\n",
        "        filename_parts = bispec_file.split('_')\n",
        "        participant = filename_parts[0]\n",
        "        emotion = filename_parts[2]\n",
        "\n",
        "        # Sampling frequency\n",
        "        fs = 44100  # Update if necessary\n",
        "\n",
        "        # Extract features\n",
        "        features = extract_bispectrum_features(bispec, fs)\n",
        "\n",
        "        # Add additional information to features\n",
        "        features['participant'] = participant\n",
        "        features['participant_type'] = participant_type\n",
        "        features['session'] = session\n",
        "        features['emotion'] = emotion\n",
        "\n",
        "        # Append features and label to lists\n",
        "        feature_list.append(features)\n",
        "        label_list.append(label)\n",
        "\n",
        "# Create DataFrame from feature list\n",
        "df_features = pd.DataFrame(feature_list)\n",
        "df_features['label'] = label_list\n",
        "\n",
        "# List of feature columns\n",
        "feature_columns = [\n",
        "    'mean_mag', 'max_mag', 'sum_mag', 'spectral_flatness', 'entropy_mag',\n",
        "    'mean_phase', 'std_phase', 'skew_phase', 'kurt_phase',\n",
        "    'qpc_strength', 'qpc_freq1', 'qpc_freq2',\n",
        "    'band_energy_low', 'band_energy_mid', 'band_energy_high',\n",
        "    'num_peaks',\n",
        "    'std_mag', 'skew_mag', 'kurt_mag'\n",
        "]\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "df_features[feature_columns] = scaler.fit_transform(df_features[feature_columns])\n",
        "\n",
        "# Save the DataFrame with features to a CSV file\n",
        "df_features.to_csv('bispectrum_features.csv', index=False)\n",
        "print(\"Features saved to 'bispectrum_features.csv'\")\n",
        "\n",
        "# Now you have your feature matrix X and labels y\n",
        "X = df_features[feature_columns].values\n",
        "y = df_features['label'].values\n",
        "\n",
        "# Proceed with machine learning modeling\n",
        "# For example, train a Random Forest classifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "xQFHGc5iWh_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GttiZq6tyWEK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_bispectrum(bispec_data, nfft, fs=1):\n",
        "    \"\"\"\n",
        "    Plot the bispectrum data using contour plot, replicating the MATLAB bispecd function.\n",
        "\n",
        "    Parameters:\n",
        "    bispec_data: 2D numpy array of bispectrum data (nfft x nfft)\n",
        "    nfft: FFT length used in bispectrum computation\n",
        "    fs: Sampling frequency (Hz), default is 1 as in MATLAB code\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the frequency axis (waxis)\n",
        "    if nfft % 2 == 0:\n",
        "        waxis = np.arange(-nfft//2, nfft//2) / nfft\n",
        "    else:\n",
        "        waxis = np.arange(-(nfft-1)//2, (nfft+1)//2) / nfft\n",
        "\n",
        "    # Adjust waxis for sampling frequency\n",
        "    waxis = waxis * fs\n",
        "\n",
        "    # Shift the bispectrum data\n",
        "    bispec_data_shifted = np.fft.fftshift(bispec_data)\n",
        "\n",
        "    # Create meshgrid for plotting\n",
        "    F1, F2 = np.meshgrid(waxis, waxis)\n",
        "\n",
        "    # Plot the contour of the magnitude of the bispectrum\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    contour_levels = 4  # Number of contour levels\n",
        "    plt.contour(F1, F2, np.abs(bispec_data_shifted), levels=contour_levels)\n",
        "    plt.grid(True)\n",
        "    plt.title('Bispectrum estimated via the direct (FFT) method')\n",
        "    plt.xlabel('f1 (Hz)')\n",
        "    plt.ylabel('f2 (Hz)')\n",
        "\n",
        "    # Set axis limits (adjust according to your data)\n",
        "    fmin = -0.001 * fs\n",
        "    fmax = 0.1 * fs\n",
        "    plt.xlim(fmin, fmax)\n",
        "    plt.ylim(fmin, fmax)\n",
        "\n",
        "    # Overlay lines\n",
        "    # Line f1 = f2\n",
        "    x_line = np.linspace(max(0, fmin), fmax, 500)\n",
        "    plt.plot(x_line, x_line, 'r', label='f1 = f2')\n",
        "\n",
        "    # Line f1 + f2 = fs / 2\n",
        "    f1_line = np.linspace(max(0, fmin), fmax, 500)\n",
        "    f2_line = (fs / 2) - f1_line\n",
        "    # Only plot where f2_line is within the axis limits\n",
        "    valid_idx = (f2_line >= fmin) & (f2_line <= fmax)\n",
        "    plt.plot(f1_line[valid_idx], f2_line[valid_idx], 'r', label='f1 + f2 = fs / 2')\n",
        "\n",
        "    # Line f2 = 0\n",
        "    plt.plot([fmin, fmax], [0, 0], 'r', label='f2 = 0')\n",
        "\n",
        "    # Add legend\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip data\n",
        "!unzip /content/bispectrum_data.zip -d /content/Bispectorum_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPK8pDZxdKZD",
        "outputId": "9b7cb96c-5f65-4826-eb07-6d9608839370"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/bispectrum_data.zip\n",
            "warning [/content/bispectrum_data.zip]:  2097152 extra bytes at beginning or within zipfile\n",
            "  (attempting to process anyway)\n",
            "file #1:  bad zipfile offset (local header sig):  2097152\n",
            "  (attempting to re-compensate)\n",
            "   creating: /content/Bispectorum_data/interview/HC/\n",
            "error: invalid zip file with overlapped components (possible zip bomb)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Path to a bispectrum data file\n",
        "bispec_file_path = '/path/to/your/bispectrum_data.npy'\n",
        "\n",
        "# Load the bispectrum data\n",
        "bispec_data = np.load(bispec_file_path)\n"
      ],
      "metadata": {
        "id": "cJvbWpA4QXtP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}