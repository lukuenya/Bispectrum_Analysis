{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1mQpNB3JJ8u95z7fGknV35IA6UN_mEKpm",
      "authorship_tag": "ABX9TyP35fi9Hg9AQ+jhaqypKH1b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukuenya/Bispectrum_Analysis/blob/master/bispec_data_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iwmX36W2YsJE"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/audio_lanzhou_2015_org.zip\" -d \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/data.zip\" -d \"/content/data\""
      ],
      "metadata": {
        "id": "Xfilv-zlq_Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "from scipy.stats import entropy, skew, kurtosis\n",
        "import pandas as pd\n",
        "import cupy as cp\n",
        "import cupyx.scipy.signal as cusignal\n",
        "import cupyx.scipy.fft as cufft\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile  # Reading audio files can remain on CPU"
      ],
      "metadata": {
        "id": "aSUQiMVYY5h9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fs = 44100  # Sampling frequency in Hz\n",
        "nfft = 512  # Adjust as needed\n",
        "\n",
        "# # Compute frequency bins once since fs is constant\n",
        "# freqs = np.fft.fftfreq(nfft, d=1/fs)\n",
        "\n",
        "\n",
        "def compute_bispectrum_gpu(audio_data, nfft=256, noverlap=50):\n",
        "    \"\"\"\n",
        "    Compute the bispectrum of an audio signal using GPU acceleration.\n",
        "\n",
        "    Parameters:\n",
        "    - audio_data: 1D numpy array of audio samples.\n",
        "    - nfft: FFT length.\n",
        "    - noverlap: Number of points to overlap between segments.\n",
        "\n",
        "    Returns:\n",
        "    - bispec: Bispectrum array on GPU.\n",
        "    \"\"\"\n",
        "    if noverlap is None:\n",
        "        noverlap = nfft // 2\n",
        "\n",
        "    # Generate window function on CPU\n",
        "    window_cpu = np.hanning(nfft)\n",
        "\n",
        "    # Segment the data on CPU\n",
        "    step = nfft - noverlap\n",
        "    shape = ((audio_data.size - noverlap) // step, nfft)\n",
        "    strides = (audio_data.strides[0] * step, audio_data.strides[0])\n",
        "    segments_cpu = np.lib.stride_tricks.as_strided(audio_data, shape=shape, strides=strides)\n",
        "\n",
        "    # Apply window function on CPU\n",
        "    segments_cpu = segments_cpu * window_cpu\n",
        "\n",
        "    # Transfer windowed segments to GPU\n",
        "    segments_gpu = cp.asarray(segments_cpu)\n",
        "\n",
        "    # Compute FFT on GPU\n",
        "    fft_segments = cufft.fft(segments_gpu, n=nfft, axis=1)\n",
        "\n",
        "    # Initialize bispectrum accumulator on GPU\n",
        "    bispec_accum = cp.zeros((nfft, nfft), dtype=cp.complex128)\n",
        "\n",
        "    # Compute bispectrum on GPU\n",
        "    num_segments = fft_segments.shape[0]\n",
        "    for i in range(num_segments):\n",
        "        X = fft_segments[i]\n",
        "        X_conj = cp.conj(X)\n",
        "        # Compute the triple product\n",
        "        outer_prod = X[:, None] * X[None, :]  # Outer product X(f1) * X(f2)\n",
        "        sum_indices = (cp.arange(nfft)[:, None] + cp.arange(nfft)) % nfft  # Indices for X*(f1 + f2)\n",
        "        X_sum_conj = X_conj[sum_indices]\n",
        "        bispec_accum += outer_prod * X_sum_conj\n",
        "\n",
        "    # Average over segments\n",
        "    bispec = bispec_accum / num_segments\n",
        "\n",
        "    return bispec\n"
      ],
      "metadata": {
        "id": "uigj3UagZMeV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio_files_gpu(\n",
        "    dataset_path,\n",
        "    participant_types,\n",
        "    emotions,\n",
        "    session,\n",
        "    nfft=512,  # or 256\n",
        "    output_dir='/content/bispec_data_RV'\n",
        "):\n",
        "    fs = 44100  # Sampling frequency in Hz\n",
        "    f_max = fs / 2  # Nyquist frequency\n",
        "    freqs = np.fft.fftfreq(nfft, d=1/fs)\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for participant_type in participant_types:\n",
        "        participant_type_path = os.path.join(dataset_path, participant_type)\n",
        "        if not os.path.exists(participant_type_path):\n",
        "            continue\n",
        "\n",
        "        # Create subdirectory for participant type in output directory\n",
        "        output_dir_participant = os.path.join(output_dir, participant_type)\n",
        "        if not os.path.exists(output_dir_participant):\n",
        "            os.makedirs(output_dir_participant)\n",
        "\n",
        "        participant_dirs = sorted(os.listdir(participant_type_path))\n",
        "\n",
        "        for participant in participant_dirs:\n",
        "            participant_path = os.path.join(participant_type_path, participant)\n",
        "            session_path = os.path.join(participant_path, session)\n",
        "            if not os.path.exists(session_path):\n",
        "                continue\n",
        "\n",
        "            for emotion in emotions:\n",
        "                emotion_path = os.path.join(session_path, emotion)\n",
        "                if not os.path.exists(emotion_path):\n",
        "                    continue\n",
        "\n",
        "                audio_files = [f for f in os.listdir(emotion_path) if f.endswith('.wav')]\n",
        "\n",
        "                # Initialize variables for accumulating bispectra\n",
        "                total_bispec_gpu = None\n",
        "                file_count = 0\n",
        "\n",
        "                for audio_file in audio_files:\n",
        "                    file_path = os.path.join(emotion_path, audio_file)\n",
        "                    try:\n",
        "                        fs_read, audio_data = wavfile.read(file_path)\n",
        "                        # Ensure audio_data is mono\n",
        "                        if audio_data.ndim > 1:\n",
        "                            audio_data = audio_data[:, 0]  # Use the first channel\n",
        "                        audio_data = audio_data.astype(np.float64)\n",
        "\n",
        "                        # Compute bispectrum using GPU\n",
        "                        bispec_gpu = compute_bispectrum_gpu(audio_data, nfft=nfft)\n",
        "\n",
        "                        # Accumulate bispectra\n",
        "                        if total_bispec_gpu is None:\n",
        "                            total_bispec_gpu = bispec_gpu\n",
        "                        else:\n",
        "                            total_bispec_gpu += bispec_gpu\n",
        "\n",
        "                        file_count += 1\n",
        "\n",
        "                        # Free GPU memory for this iteration\n",
        "                        del bispec_gpu\n",
        "                        cp._default_memory_pool.free_all_blocks()\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error processing {file_path}: {e}\")\n",
        "                        continue\n",
        "\n",
        "                # After processing all files for this participant, session, and emotion\n",
        "                if file_count > 0:\n",
        "                    # Compute the average bispectrum\n",
        "                    avg_bispec_gpu = total_bispec_gpu / file_count\n",
        "                    avg_bispec = avg_bispec_gpu.get()  # Transfer to CPU\n",
        "\n",
        "                    # Create meshgrid for f1 and f2 (in Hz)\n",
        "                    f_indices = np.arange(nfft)\n",
        "                    f1_indices, f2_indices = np.meshgrid(f_indices, f_indices, indexing='ij')\n",
        "\n",
        "                    f1_freqs = freqs[f1_indices]\n",
        "                    f2_freqs = freqs[f2_indices]\n",
        "\n",
        "                    # Create mask for the primary region based on the new conditions\n",
        "                    primary_region_mask = (\n",
        "                        (f1_freqs >= 0) &\n",
        "                        (f2_freqs >= 0) &\n",
        "                        (f1_freqs + f2_freqs <= f_max) &\n",
        "                        (f1_freqs <= f2_freqs)\n",
        "                    )\n",
        "\n",
        "                    # Initialize the primary region bispectrum with NaNs or zeros to maintain 2D shape\n",
        "                    avg_bispec_primary = np.full_like(avg_bispec, np.nan)  # Use np.nan or 0 if preferred\n",
        "                    avg_bispec_primary[primary_region_mask] = avg_bispec[primary_region_mask]\n",
        "\n",
        "                    # Save the bispectrum data for the primary region (2D)\n",
        "                    data_filename = f'{participant}_{session}_{emotion}_primary_bispectrum.npy'\n",
        "                    data_save_path = os.path.join(output_dir_participant, data_filename)\n",
        "                    np.save(data_save_path, avg_bispec_primary)\n",
        "                    print(f\"Primary region bispectrum data saved to {data_save_path}\")\n",
        "\n",
        "                    # Free GPU memory\n",
        "                    del avg_bispec_gpu, total_bispec_gpu\n",
        "                    cp._default_memory_pool.free_all_blocks()\n",
        "                else:\n",
        "                    print(f\"No valid audio files processed for {participant} - {session} - {emotion}\")\n"
      ],
      "metadata": {
        "id": "Hhgb-DFiZfQ2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataset path and parameters\n",
        "dataset_path = '/content/audio_lanzhou_2015_org'  # Update this path\n",
        "participant_types = ['MDD', 'HC']\n",
        "emotions = ['Positive', 'Neutral', 'Negative']\n",
        "session = 'Read_Vocabulary' # or 'Interview'\n",
        "nfft = 512 # or 256 Adjust as needed\n",
        "\n",
        "# Define the output directories\n",
        "output_dir = '/content/bispec_data_RV'  # Update this path\n",
        "output_plot_dir = '/content/plots_RV'  # Update this path\n",
        "\n",
        "# Call the function to process audio files and save averaged bispectrum data and plots\n",
        "process_audio_files_gpu(\n",
        "    dataset_path,\n",
        "    participant_types,\n",
        "    emotions,\n",
        "    session,\n",
        "    nfft=nfft,\n",
        "    output_dir=output_dir,\n",
        "    #output_plot_dir=output_plot_dir\n",
        ")"
      ],
      "metadata": {
        "id": "ue6MGMD1bJfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def extract_bispectrum_features(bispec, fs):\n",
        "#     import numpy as np\n",
        "#     from scipy.stats import entropy, skew, kurtosis\n",
        "\n",
        "#     # Compute magnitude and phase\n",
        "#     bispec_magnitude = np.abs(bispec)\n",
        "#     bispec_phase = np.angle(bispec)\n",
        "\n",
        "#     # Flatten the bispectrum magnitude and phase, removing NaNs\n",
        "#     bispec_mag_flat = bispec_magnitude.flatten()\n",
        "#     bispec_phase_flat = bispec_phase.flatten()\n",
        "\n",
        "#     # Remove NaNs for calculations\n",
        "#     bispec_mag_flat = bispec_mag_flat[~np.isnan(bispec_mag_flat)]\n",
        "#     bispec_phase_flat = bispec_phase_flat[~np.isnan(bispec_phase_flat)]\n",
        "\n",
        "#     # Check if the flattened array is empty after removing NaNs\n",
        "#     if bispec_mag_flat.size == 0 or bispec_phase_flat.size == 0:\n",
        "#         print(\"Bispectrum is empty after removing NaNs.\")\n",
        "#         return {}\n",
        "\n",
        "#     # Avoid log(0) by adding a small epsilon\n",
        "#     eps = 1e-12\n",
        "\n",
        "#     # Bispectral Magnitude Features\n",
        "#     mean_mag = np.nanmean(bispec_mag_flat)\n",
        "#     max_mag = np.nanmax(bispec_mag_flat)\n",
        "#     sum_mag = np.nansum(bispec_mag_flat)\n",
        "#     spectral_flatness = np.exp(np.nanmean(np.log(bispec_mag_flat + eps))) / (mean_mag + eps)\n",
        "#     entropy_mag = entropy(bispec_mag_flat + eps)\n",
        "\n",
        "#     # Bispectral Phase Features\n",
        "#     mean_phase = np.nanmean(bispec_phase_flat)\n",
        "#     std_phase = np.nanstd(bispec_phase_flat)\n",
        "#     skew_phase = skew(bispec_phase_flat)\n",
        "#     kurt_phase = kurtosis(bispec_phase_flat)\n",
        "\n",
        "#     # Quadratic Phase Coupling Features\n",
        "#     N = bispec.shape[0]\n",
        "#     if bispec_magnitude.size > 0:\n",
        "#         indices_qpc = np.unravel_index(np.nanargmax(bispec_magnitude), bispec_magnitude.shape)\n",
        "#         qpc_strength = bispec_magnitude[indices_qpc]\n",
        "#         qpc_freqs = (indices_qpc[0] * fs / N, indices_qpc[1] * fs / N)\n",
        "#     else:\n",
        "#         qpc_strength = 0\n",
        "#         qpc_freqs = (0, 0)\n",
        "\n",
        "#     # Frequency Band Features\n",
        "#     freq_bins = np.fft.fftfreq(N, d=1/fs)\n",
        "#     freq_bins = freq_bins[:N//2]\n",
        "#     bispec_magnitude_half = bispec_magnitude[:N//2, :N//2]\n",
        "\n",
        "#     bands = {\n",
        "#         'low': (0, 1000),\n",
        "#         'mid': (1000, 5000),\n",
        "#         'high': (5000, fs/2)\n",
        "#     }\n",
        "\n",
        "#     band_energies = {}\n",
        "#     for band_name, (fmin, fmax) in bands.items():\n",
        "#         idx = np.where((freq_bins >= fmin) & (freq_bins < fmax))[0]\n",
        "#         if len(idx) > 0:\n",
        "#             band_energy = np.nansum(bispec_magnitude_half[np.ix_(idx, idx)])\n",
        "#         else:\n",
        "#             band_energy = 0\n",
        "#         band_energies[f'band_energy_{band_name}'] = band_energy\n",
        "\n",
        "#     # Bispectrum Peaks\n",
        "#     threshold = mean_mag + 2 * np.nanstd(bispec_mag_flat)\n",
        "#     num_peaks = np.sum(bispec_mag_flat > threshold)\n",
        "\n",
        "#     # Statistical Features\n",
        "#     std_mag = np.nanstd(bispec_mag_flat)\n",
        "#     skew_mag = skew(bispec_mag_flat)\n",
        "#     kurt_mag = kurtosis(bispec_mag_flat)\n",
        "\n",
        "#     # Collect all features into a dictionary\n",
        "#     features = {\n",
        "#         'mean_mag': mean_mag,\n",
        "#         'max_mag': max_mag,\n",
        "#         'sum_mag': sum_mag,\n",
        "#         'spectral_flatness': spectral_flatness,\n",
        "#         'entropy_mag': entropy_mag,\n",
        "#         'mean_phase': mean_phase,\n",
        "#         'std_phase': std_phase,\n",
        "#         'skew_phase': skew_phase,\n",
        "#         'kurt_phase': kurt_phase,\n",
        "#         'qpc_strength': qpc_strength,\n",
        "#         'qpc_freq1': qpc_freqs[0],\n",
        "#         'qpc_freq2': qpc_freqs[1],\n",
        "#         **band_energies,\n",
        "#         'num_peaks': num_peaks,\n",
        "#         'std_mag': std_mag,\n",
        "#         'skew_mag': skew_mag,\n",
        "#         'kurt_mag': kurt_mag,\n",
        "#     }\n",
        "\n",
        "#     return features\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "def extract_bispectrum_features(bispec, fs):\n",
        "    import numpy as np\n",
        "    from scipy.stats import entropy, skew, kurtosis\n",
        "\n",
        "    # Compute magnitude and phase\n",
        "    bispec_magnitude = np.abs(bispec)\n",
        "    bispec_phase = np.angle(bispec)\n",
        "\n",
        "    # Flatten the bispectrum magnitude and phase, removing NaNs\n",
        "    bispec_mag_flat = bispec_magnitude.flatten()\n",
        "    bispec_phase_flat = bispec_phase.flatten()\n",
        "\n",
        "    # Remove NaNs for calculations\n",
        "    bispec_mag_flat = bispec_mag_flat[~np.isnan(bispec_mag_flat)]\n",
        "    bispec_phase_flat = bispec_phase_flat[~np.isnan(bispec_phase_flat)]\n",
        "\n",
        "    # Check if the flattened array is empty after removing NaNs\n",
        "    if bispec_mag_flat.size == 0 or bispec_phase_flat.size == 0:\n",
        "        print(\"Bispectrum is empty after removing NaNs.\")\n",
        "        return {}\n",
        "\n",
        "    # Avoid log(0) by adding a small epsilon\n",
        "    eps = 1e-12\n",
        "\n",
        "    # Bispectral Magnitude Features\n",
        "    mean_mag = np.nanmean(bispec_mag_flat)\n",
        "    max_mag = np.nanmax(bispec_mag_flat)\n",
        "    sum_mag = np.nansum(bispec_mag_flat)\n",
        "    std_mag = np.nanstd(bispec_mag_flat)\n",
        "    skew_mag = skew(bispec_mag_flat)\n",
        "    kurt_mag = kurtosis(bispec_mag_flat)\n",
        "    spectral_flatness = np.exp(np.nanmean(np.log(bispec_mag_flat + eps))) / (mean_mag + eps)\n",
        "    entropy_mag = entropy(bispec_mag_flat + eps)\n",
        "\n",
        "    # Bispectral Phase Features\n",
        "    mean_phase = np.nanmean(bispec_phase_flat)\n",
        "    std_phase = np.nanstd(bispec_phase_flat)\n",
        "    skew_phase = skew(bispec_phase_flat)\n",
        "    kurt_phase = kurtosis(bispec_phase_flat)\n",
        "\n",
        "    # Quadratic Phase Coupling Features\n",
        "    N = bispec.shape[0]\n",
        "    if bispec_magnitude.size > 0:\n",
        "        indices_qpc = np.unravel_index(np.nanargmax(bispec_magnitude), bispec_magnitude.shape)\n",
        "        qpc_strength = bispec_magnitude[indices_qpc]\n",
        "        qpc_freqs = (indices_qpc[0] * fs / (N * 2), indices_qpc[1] * fs / (N * 2))\n",
        "    else:\n",
        "        qpc_strength = 0\n",
        "        qpc_freqs = (0, 0)\n",
        "    qpc_freq1, qpc_freq2 = qpc_freqs\n",
        "\n",
        "    # Frequency Band Features\n",
        "    freq_bins = np.fft.fftfreq(N * 2, d=1/fs)[:N]  # Assuming bispec is half-sized, N frequencies\n",
        "    bispec_magnitude_half = bispec_magnitude  # Since bispec is already half-sized\n",
        "\n",
        "    bands = {\n",
        "        'low': (0, 1000),\n",
        "        'mid': (1000, 5000),\n",
        "        'high': (5000, fs/2)\n",
        "    }\n",
        "\n",
        "    band_energies = {}\n",
        "    for band_name, (fmin, fmax) in bands.items():\n",
        "        idx = np.where((freq_bins >= fmin) & (freq_bins < fmax))[0]\n",
        "        if len(idx) > 0:\n",
        "            band_energy = np.nansum(bispec_magnitude_half[np.ix_(idx, idx)])\n",
        "        else:\n",
        "            band_energy = 0\n",
        "        band_energies[f'band_energy_{band_name}'] = band_energy\n",
        "\n",
        "    # Bispectrum Peaks\n",
        "    threshold = mean_mag + 2 * std_mag\n",
        "    peaks_indices = np.where(bispec_mag_flat > threshold)[0]\n",
        "    num_peaks = len(peaks_indices)\n",
        "\n",
        "    # If peaks are found, compute additional features\n",
        "    if num_peaks > 0:\n",
        "        peak_magnitudes = bispec_mag_flat[peaks_indices]\n",
        "        max_peak_intensity = np.nanmax(peak_magnitudes)\n",
        "        mean_peak_intensity = np.nanmean(peak_magnitudes)\n",
        "        median_peak_intensity = np.nanmedian(peak_magnitudes)\n",
        "        std_peak_intensity = np.nanstd(peak_magnitudes)\n",
        "        skew_peak_intensity = skew(peak_magnitudes)\n",
        "        kurt_peak_intensity = kurtosis(peak_magnitudes)\n",
        "    else:\n",
        "        max_peak_intensity = 0\n",
        "        mean_peak_intensity = 0\n",
        "        median_peak_intensity = 0\n",
        "        std_peak_intensity = 0\n",
        "        skew_peak_intensity = 0\n",
        "        kurt_peak_intensity = 0\n",
        "\n",
        "    # Reshape bispectrum magnitude to 2D for peak location analysis\n",
        "    bispec_magnitude_2d = bispec_magnitude  # Assuming it's already 2D\n",
        "\n",
        "    # Get the coordinates of the peaks\n",
        "    peak_coords = np.argwhere(bispec_magnitude_2d > threshold)\n",
        "\n",
        "    # Frequencies corresponding to the bispectrum axes\n",
        "    freqs = freq_bins  # frequencies corresponding to the axes\n",
        "\n",
        "    # Extract frequencies of the top N peaks\n",
        "    N_peaks = 5  # Number of top peaks to consider\n",
        "    if num_peaks > 0:\n",
        "        # Sort peaks by magnitude\n",
        "        sorted_peak_indices = np.argsort(-peak_magnitudes)\n",
        "        top_n_indices = peaks_indices[sorted_peak_indices[:N_peaks]]\n",
        "        # Convert flat indices back to 2D coordinates\n",
        "        top_n_coords = np.unravel_index(top_n_indices, bispec_magnitude_2d.shape)\n",
        "        top_n_freqs = [(freqs[i], freqs[j]) for i, j in zip(*top_n_coords)]\n",
        "    else:\n",
        "        top_n_freqs = []\n",
        "\n",
        "    # Collect all features into a dictionary\n",
        "    features = {\n",
        "        'mean_mag': mean_mag,\n",
        "        'max_mag': max_mag,\n",
        "        'sum_mag': sum_mag,\n",
        "        'std_mag': std_mag,\n",
        "        'skew_mag': skew_mag,\n",
        "        'kurt_mag': kurt_mag,\n",
        "        'spectral_flatness': spectral_flatness,\n",
        "        'entropy_mag': entropy_mag,\n",
        "        'mean_phase': mean_phase,\n",
        "        'std_phase': std_phase,\n",
        "        'skew_phase': skew_phase,\n",
        "        'kurt_phase': kurt_phase,\n",
        "        'qpc_strength': qpc_strength,\n",
        "        'qpc_freq1': qpc_freq1,\n",
        "        'qpc_freq2': qpc_freq2,\n",
        "        **band_energies,\n",
        "        'num_peaks': num_peaks,\n",
        "        'max_peak_intensity': max_peak_intensity,\n",
        "        'mean_peak_intensity': mean_peak_intensity,\n",
        "        'median_peak_intensity': median_peak_intensity,\n",
        "        'std_peak_intensity': std_peak_intensity,\n",
        "        'skew_peak_intensity': skew_peak_intensity,\n",
        "        'kurt_peak_intensity': kurt_peak_intensity,\n",
        "    }\n",
        "\n",
        "    # Add frequencies of top N peaks to the features\n",
        "    for idx, (f1, f2) in enumerate(top_n_freqs):\n",
        "        features[f'top_peak_{idx+1}_freq1'] = f1\n",
        "        features[f'top_peak_{idx+1}_freq2'] = f2\n",
        "\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "2dCF26yZSJgS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths and parameters\n",
        "output_dir = '/content/bispec_data_RV'  # Update with your output directory\n",
        "session = 'Read_Vocabulary' # or 'Interview'\n",
        "participant_types = ['MDD', 'HC']\n",
        "emotions = ['Positive', 'Neutral', 'Negative']\n",
        "\n",
        "# Initialize a list to store features\n",
        "features_list = []\n",
        "\n",
        "# Load bispectrum data and extract features\n",
        "for participant_type in participant_types:\n",
        "    participant_output_dir = os.path.join(output_dir, participant_type)\n",
        "    if not os.path.exists(participant_output_dir):\n",
        "        continue\n",
        "\n",
        "    # Assign label based on participant type\n",
        "    label = 1 if participant_type == 'MDD' else 0\n",
        "\n",
        "    # List participants in the directory\n",
        "    participant_files = os.listdir(participant_output_dir)\n",
        "    for bispec_file in participant_files:\n",
        "        bispec_path = os.path.join(participant_output_dir, bispec_file)\n",
        "\n",
        "        # Ensure we're only processing .npy files\n",
        "        if not bispec_file.endswith('_primary_bispectrum.npy'):\n",
        "            continue\n",
        "\n",
        "        # Load bispectrum data\n",
        "        bispec = np.load(bispec_path)\n",
        "\n",
        "        # Extract participant ID and emotion from filename\n",
        "        filename_parts = bispec_file.split('_')\n",
        "        participant = filename_parts[0]\n",
        "        emotion = filename_parts[3] if session == 'Read_Vocabulary' else filename_parts[2]\n",
        "\n",
        "        # Sampling frequency\n",
        "        fs = 44100  # Update if necessary\n",
        "\n",
        "        # Extract features\n",
        "        features = extract_bispectrum_features(bispec, fs)\n",
        "\n",
        "        # Add additional information to features\n",
        "        features['participant'] = participant\n",
        "        features['participant_type'] = participant_type\n",
        "        features['session'] = session\n",
        "        features['emotion'] = emotion\n",
        "        features['label'] = label\n",
        "\n",
        "        # Append features to the list\n",
        "        features_list.append(features)\n",
        "\n",
        "# Convert the list of features to a DataFrame\n",
        "df_features = pd.DataFrame(features_list)\n",
        "\n",
        "# Save the DataFrame to an Excel or CSV file\n",
        "excel_file = '/content/features_RV.xlsx'  # Update the path\n",
        "df_features.to_excel(excel_file, index=False)\n",
        "print(f\"Features saved to {excel_file}\")\n",
        "\n",
        "# # Optionally, save to CSV\n",
        "# csv_file = '/path/to/features.csv'  # Update the path\n",
        "# df_features.to_csv(csv_file, index=False)\n",
        "# print(f\"Features saved to {csv_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L0TeMebbdh2",
        "outputId": "d937ce6b-cda2-4928-f72c-0d4b7c56f543"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features saved to /content/features_RV.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/bispec_data_Interview', 'zip', '/content/bispec_data_Interview')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fuUt7z3Jn7yJ",
        "outputId": "c1597e32-5b45-4606-f0fd-5dd8c2dd9cba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/bispec_data_Interview.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}